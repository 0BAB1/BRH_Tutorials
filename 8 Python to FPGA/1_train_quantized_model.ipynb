{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71a8839-7c58-4862-a5f0-0f7e97085918",
   "metadata": {},
   "source": [
    "# THIS NOTEBOOK TRAINS A FASHION-MNIST MODEL USING 0-255 VALUES (UINT8)\n",
    "\n",
    "> Note that the end model, oexported in a FINN-ONNX format will be Quantized. Quantization is handled by Brevitas.\n",
    "\n",
    "After creating the docker environement,\n",
    "\n",
    "The goal is to create a MNIST Fasion model in pytorch and experiment with the different parameters\n",
    "\n",
    "Then, we will do the same model but fully quantized and start adapting it for FINN\n",
    "\n",
    "> Side note : We'll use Quantization Aware Training (QAT) for this tutorial, but another possibility is to use Post-Training Quantization (PTQ) [Here is a resource to learn more but it's not really necessary for this tutorial](https://www.youtube.com/watch?v=0VdNflU08yA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a09c1a7-e82e-4d14-bced-29aaf340638c",
   "metadata": {},
   "source": [
    "## Base model creation\n",
    "\n",
    "Before going anyfurther, note that this notebook was meant to be run in the FINN docker environment, from a linux host.\n",
    "\n",
    "Use the command ```bash run-docker.sh notbook``` and use the jupyter link for your vscode/vim editor or simply open it in your browser if you like jupyter you will also need to setup you env variables right.\n",
    "\n",
    "I encourage you to check the FINN docs for this part, you can find more precise guidelines in the resources of the main [readme](./README.md).\n",
    "\n",
    "> Don't forget to use your own username below. ```root_dir = f\"/tmp/finn_dev_{user_name}\"``` is the common mounted folder where you'll be able to access all outputs from the FINN docker container from you host machine to then use it for further treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e9dec1-299c-45ec-bc1a-41d4825fea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/finn_dev_rootmin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "user_name = \"rootmin\" # REPLACE THIS WITH YOUR HOST MACHINE USER NAME \n",
    "root_dir = f\"/tmp/finn_dev_{user_name}\"\n",
    "\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5934e06",
   "metadata": {},
   "source": [
    "Import the data and transform it, we don't normalize to really make it as simple as possible, the only transformation is to convert it to a pytorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9651dd1-25d9-4c48-8e02-08c28d29fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    #transforms.Normalize((0.5,), (0.5,))  # Normalize the tensor with mean and std\n",
    "]);\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data',  # Directory to save the dataset\n",
    "    train=True,  # Load the training set\n",
    "    download=True,  # Download the dataset if it doesn't exist\n",
    "    transform=transform  # Apply the defined transformations\n",
    ");\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,  # Load the test set\n",
    "    download=True,\n",
    "    transform=transform\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ba53e",
   "metadata": {},
   "source": [
    "Let's visualize the data a little bit... We see the data is ranging from 0 to 1 but we know our FPGA AI model IP will expect INTEGER values... More on that later !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb48f47-1369-4f87-8c9b-c0e29a8de5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min :  0.0  /// Max :  0.78039217\n",
      "Data type : float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image, label = train_dataset[5]\n",
    "image = np.array(image).squeeze()\n",
    "print(\"Min : \", np.min(image[0]), \" /// Max : \", np.max(image[0]))\n",
    "print(\"Data type :\", image[0].dtype)\n",
    "# plot the sample\n",
    "\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1648a989-431b-418d-9dbf-118ca52aa7e1",
   "metadata": {},
   "source": [
    "# Actual QNN\n",
    "\n",
    "> QNN = Quantized Neural Network\n",
    "\n",
    "That's what we are about to do using Quantized Aware Training, and the best part is Brevitas handles all of it in the background !\n",
    "\n",
    "This part is about creating a quantized version of the model and adapting it to finn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab5b0a0-9cfd-41c7-99cc-3c2d3365cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from brevitas.nn import QuantLinear\n",
    "from brevitas.nn import QuantReLU\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "brevitas_input_size = 28 * 28\n",
    "brevitas_hidden1 = 64\n",
    "brevitas_hidden2 = 64\n",
    "brevitas_num_classes = 10\n",
    "weight_bit_width = 4\n",
    "act_bit_width = 4\n",
    "dropout_prob = 0.5\n",
    "\n",
    "#is this model fully quantized or only the wieghts, i shall dig to find out once done !\n",
    "brevitas_model = nn.Sequential(\n",
    "    QuantLinear(brevitas_input_size, brevitas_hidden1, bias=True, weight_bit_width=weight_bit_width),\n",
    "    nn.BatchNorm1d(brevitas_hidden1),\n",
    "    nn.Dropout(0.5),\n",
    "    QuantReLU(bit_width=act_bit_width),\n",
    "    QuantLinear(brevitas_hidden1, brevitas_hidden2, bias=True, weight_bit_width=weight_bit_width),\n",
    "    nn.BatchNorm1d(brevitas_hidden2),\n",
    "    nn.Dropout(0.5),\n",
    "    QuantReLU(bit_width=act_bit_width),\n",
    "    QuantLinear(brevitas_hidden2, brevitas_num_classes, bias=True, weight_bit_width=weight_bit_width),\n",
    "    QuantReLU(bit_width=act_bit_width)\n",
    ")\n",
    "\n",
    "# uncomment to check the network object\n",
    "# brevitas_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289eec74",
   "metadata": {},
   "source": [
    "### The input data has to be quantized.\n",
    "\n",
    "Normaly in brevistas, we can use the ```QuantIdentity()``` layer for this but unfortunatly, it does not convert to hardware (yet) in FINN.\n",
    "\n",
    "It its really not a problem, as we can just quantize the input data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670acb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define a custom quantization function\n",
    "def quantize_tensor(x, num_bits=8):\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "    min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    scale = (max_val - min_val) / (qmax - qmin)\n",
    "    initial_zero_point = qmin - min_val / scale\n",
    "\n",
    "    zero_point = 0\n",
    "    if initial_zero_point < qmin:\n",
    "        zero_point = qmin\n",
    "    elif initial_zero_point > qmax:\n",
    "        zero_point = qmax\n",
    "    else:\n",
    "        zero_point = initial_zero_point\n",
    "\n",
    "    zero_point = int(zero_point)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    \n",
    "    return q_x\n",
    "\n",
    "# Define the quantized transform\n",
    "transform_quantized = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Lambda(lambda x: quantize_tensor(x))  # Apply quantization\n",
    "])\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset_qnt = datasets.FashionMNIST(\n",
    "    root='./data',  # Directory to save the dataset\n",
    "    train=True,  # Load the training set\n",
    "    download=True,  # Download the dataset if it doesn't exist\n",
    "    transform=transform_quantized  # Apply the defined transformations\n",
    ");\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset_qnt = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,  # Load the test set\n",
    "    download=True,\n",
    "    transform=transform_quantized\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset_qnt, 100)\n",
    "test_loader = DataLoader(test_dataset_qnt, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84a0bd",
   "metadata": {},
   "source": [
    "Let's re-visualize the data now... That's better !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c819d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min :  0.0  /// Max :  255.0\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image, label = train_dataset_qnt[10]\n",
    "image = np.array(image).squeeze()\n",
    "print(\"Min : \", np.min(image), \" /// Max : \", np.max(image))\n",
    "print(image.dtype)\n",
    "\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a58259",
   "metadata": {},
   "source": [
    "## Actual training\n",
    "\n",
    "Now, just like in a regular PyTorch workflow, we train the model using a simple trainng loop.\n",
    "\n",
    "Note that it takes a bit of time because\n",
    "- We train on CPU\n",
    "- QAT \"simulates\" Quantization using quant/dequant layers (so the model becomes robust to quantization, which is not the case in PTQ) and backpropagation is different and that takes up computing power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236d85fe-986a-44f4-84d1-fce1d5591f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:1255: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1758.)\n",
      "  return super(Tensor, self).rename(names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6401\n",
      "Epoch [2/5], Loss: 0.4895\n",
      "Epoch [3/5], Loss: 0.5153\n",
      "Epoch [4/5], Loss: 0.6120\n",
      "Epoch [5/5], Loss: 0.3428\n"
     ]
    }
   ],
   "source": [
    "# loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(brevitas_model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "num_epochs = 5\n",
    "brevitas_model.train()\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = torch.reshape(images, (batch_size, 28*28))\n",
    "        out = brevitas_model(images.float()) # This just make the value a float ie 255 becomes 255,0 and not 1\n",
    "        loss = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/5], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7ee17",
   "metadata": {},
   "source": [
    "We now test the model with ~85% accuracy, which is extremely close to non-quatized model performances (~85-86% when I tested it on my side when I made the course).\n",
    "\n",
    "This dataset isn't very complex though, this delta will depend on the data you have to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d239cf-edb2-4faa-a502-d05861a156fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 84.2 %\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "brevitas_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = torch.reshape(images, (batch_size, 28*28))\n",
    "        out = brevitas_model(images.float())\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(\"accuracy =\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c0b43",
   "metadata": {},
   "source": [
    "Here are some lines to execute the tensor that mmakes up the model and their different representations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3843919-1e83-4c50-accd-3e9292cecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantTensor(value=tensor([[ 0.0294, -0.0000,  0.0589,  ..., -0.0589,  0.0589,  0.0883],\n",
      "        [ 0.0294,  0.0000,  0.0294,  ..., -0.0883, -0.1471, -0.0589],\n",
      "        [-0.0589,  0.0294, -0.0294,  ...,  0.0883,  0.0883, -0.1177],\n",
      "        ...,\n",
      "        [ 0.0589,  0.0883, -0.0294,  ..., -0.0589, -0.0000,  0.0589],\n",
      "        [ 0.0589, -0.0000, -0.0294,  ...,  0.0000,  0.0294, -0.0294],\n",
      "        [-0.0294,  0.0000, -0.0589,  ...,  0.0000,  0.0294, -0.0294]],\n",
      "       grad_fn=<MulBackward0>), scale=tensor(0.0294, grad_fn=<DivBackward0>), zero_point=tensor(0.), bit_width=tensor(4.), signed_t=tensor(True), training_t=tensor(False))\n",
      "tensor([[ 1,  0,  2,  ..., -2,  2,  3],\n",
      "        [ 1,  0,  1,  ..., -3, -5, -2],\n",
      "        [-2,  1, -1,  ...,  3,  3, -4],\n",
      "        ...,\n",
      "        [ 2,  3, -1,  ..., -2,  0,  2],\n",
      "        [ 2,  0, -1,  ...,  0,  1, -1],\n",
      "        [-1,  0, -2,  ...,  0,  1, -1]], dtype=torch.int8)\n",
      "torch.int8\n"
     ]
    }
   ],
   "source": [
    "#lets have a quick look at the weights too\n",
    "print(brevitas_model[0].quant_weight())\n",
    "#internally, weoght are stored as float 32, here nare ways to visualize actual quantized weights :\n",
    "print(brevitas_model[0].quant_weight().int())\n",
    "print(brevitas_model[0].quant_weight().int().dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d9899-000b-4343-ac81-2c425b571519",
   "metadata": {},
   "source": [
    "# EXPORTING THE MODEL TO FINN-ONNX\n",
    "\n",
    "maybe you know ONNX, maybe you don't. At the end of the day, It's just a way to represent AI models (or just tensor operations) in an optimised an standard way. It also allows us to use Netron to visualize the model as a nice graph.\n",
    "\n",
    "> FINN-ONNX is just like ONNX, exept it's better for quantized models (under 8bit quantization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f27a3b-88c6-483e-be82-85d1ee53129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0\n",
      "Model saved to /tmp/finn_dev_rootmin/ready_finn.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rootmin/Documents/freelance/mission2/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.core.datatype import DataType\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "filename = root_dir + \"/part1.onnx\"\n",
    "filename_clean = root_dir + \"/part1_clean.onnx\"\n",
    "\n",
    "def asymmetric_quantize(arr, num_bits=8):\n",
    "    min = 0\n",
    "    max = 2**num_bits - 1\n",
    "    \n",
    "    beta = np.min(arr)\n",
    "    alpha = np.max(arr)\n",
    "    scale = (alpha - beta) / max\n",
    "    zero_point = np.clip((-beta/scale),0,max).round().astype(np.int8)\n",
    "\n",
    "    quantized_arr = np.clip(np.round(arr / scale + zero_point), min, max).astype(np.float32)\n",
    "    \n",
    "    return quantized_arr\n",
    "\n",
    "#Crete a tensor ressembling the input tensor we saw earlier\n",
    "input_a = np.random.rand(1,28*28).astype(np.float32)\n",
    "input_a = asymmetric_quantize(input_a)\n",
    "print(np.max(input_a[0]))\n",
    "scale = 1.0\n",
    "input_t = torch.from_numpy(input_a * scale)\n",
    "\n",
    "# Export to ONNX\n",
    "export_qonnx(\n",
    "    brevitas_model, export_path=filename, input_t=input_t\n",
    ")\n",
    "\n",
    "# clean-up\n",
    "qonnx_cleanup(filename, out_file=filename_clean)\n",
    "\n",
    "# ModelWrapper\n",
    "model = ModelWrapper(filename_clean)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(root_dir + \"/ready_finn.onnx\")\n",
    "\n",
    "print(\"Model saved to \" + root_dir + \"/ready_finn.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7e045",
   "metadata": {},
   "source": [
    "## Visualization in Netron\n",
    "\n",
    "We can now visualise our network in netron, we can clearly identify each layer in this graph, Great !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6f0250-5b1c-4276-9293-c29a1b112782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving '/tmp/finn_dev_rootmin/ready_finn.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x71736875c460>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finn.util.visualization import showInNetron\n",
    "\n",
    "showInNetron(root_dir + \"/ready_finn.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db41a1",
   "metadata": {},
   "source": [
    "We are now ready to move on to FINN !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
